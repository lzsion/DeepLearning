# 吴恩达深度学习第二课 学习笔记

> 二、网络正则化以及优化方法
> （1）视频教程：学习吴恩达deeplearning.ai系列教程中第二课和第三课所有内容。
> （2）学习目标：了解正则化方法、优化方法、数据集划分方式，学习超参数调节技巧。重点掌握mini-batch梯度下降法和batch norm正则化方法。
> （3）动手实验：完成第二课对应的课后编程作业并撰写报告，报告主要记录实验原理（mini-batch、batch norm理论推导等）、实验环境、实验结果、结果分析等。

**相关链接**
[吴恩达深度学习第二课](https://www.bilibili.com/video/BV1V441127zE/)
[作业链接1](https://zhuanlan.zhihu.com/p/95510114)
[作业链接2](https://zhuanlan.zhihu.com/p/354386182)

## week-1

### 1.1 数据集

训练集 training set  
验证集 development set (验证不同算法的效果)  
测试集 test set (评估性能)  

确保 验证集和测试集 来源与同一分布  
测试集可有可无  

### 1.2 & 1.3 偏差 和 方差

train set error
dev set error

训练集的误差比验证集小很多，过拟合，高方差  
训练集和验证集误差都较大，欠拟合，高偏差  
训练集和验证集误差都较大 且训练集的误差比验证集小很多，高方差，高偏差  
训练集和验证集误差都较小，低方差，低偏差  

偏差：训练集错误率与0%(基本/最优错误率)的差别  
方差：训练集错误率和测试集错误率之间的差别  

解决高偏差方法
    1. 训练更长时间
    2. 选择更大的网络  
    3. 找到更合适的神经网络框架

解决高方差方法
    1. 采用更多数据
    2. 正则化减少过拟合
    3. 找到更合适的神经网络框架

### 1.4 正则化 Regularization
